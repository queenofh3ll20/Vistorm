services:
  # event_listener:
  #   build:
  #     context: .
  #     dockerfile: docker_images/event_listener/Dockerfile
  #   container_name: event_listener_g
  #   env_file:
  #     - ./conf/.env
  #   volumes:
  #     - ./data/yt_out:/app/data/yt_out
  #   command: ["python", "/app/event_listener.py"]
    
  broker:
    image: apache/kafka:latest
    hostname: broker
    container_name: broker_g
    ports:
      - '9092:9092'
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT_HOST://broker:9092,PLAINTEXT://broker:19092'
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@broker:29093'
      KAFKA_LISTENERS: 'CONTROLLER://:29093,PLAINTEXT_HOST://:9092,PLAINTEXT://:19092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      CLUSTER_ID: '4L6g3nShT-eMCtK--X86sw'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "9092"]
      interval: 10s
      timeout: 5s
      retries: 3

  topic-creator:
    image: apache/kafka:latest
    container_name: topic-creator_g
    command: > 
      bash -c " sleep 2 &&
      /opt/kafka/bin/kafka-topics.sh --create --topic yt_raw --bootstrap-server broker:9092" 
    depends_on:
      - broker

  logstash:
    image: docker.elastic.co/logstash/logstash:8.17.0  # Use the latest Logstash image
    container_name: logstash_g
    environment:
      XPACK_MONITORING_ENABLED: "false"
      KAFKA_BROKER: "broker:9092"
    depends_on:
      - broker
    volumes:
      - ./conf/logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro  # Mount the Logstash config
      - ./conf/logstash/sincedb:/conf/logstash/sincedb
      - ./data/yt_out:/data/yt_out  # Mount the input folder

  kaggle-dataset:
    build:
      context: .
      dockerfile: docker_images/kaggle_dataset/dockerfile
    container_name: kaggle_dataset
    volumes:
      - ./data/kaggle:/kaggle
    command: ["python" , "/app/kaggle_dataset.py"]

  spark:
    build:
      context: .
      dockerfile: docker_images/spark/dockerfile
    container_name: spark_g
    ports:
      - "4040:4040"
    environment:
      - SPARK_DRIVER_MEMORY=2g
      - SPARK_EXECUTOR_MEMORY=2g
    volumes:
       - ./data/Spark/:/app/data/Spark
       - ./data/kaggle:/app/data/kaggle
    command: ["spark-submit", "--packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.4,org.elasticsearch:elasticsearch-spark-30_2.12:8.17.0", "/app/processing.py"]
    depends_on:
      broker:
        condition: service_healthy
      #elasticsearch:
      #  condition: service_healthy
      # mllib:
      #   condition: service_completed_successfully
    mem_limit: 4g

  # mllib:
  #   build:
  #     context: .
  #     dockerfile: docker_images/MLlib/dockerfile
  #   container_name: MLlib
  #   ports:
  #     - "4041:4041"
  #   environment:
  #     - SPARK_DRIVER_MEMORY=2g
  #     - SPARK_EXECUTOR_MEMORY=2g
  #   volumes:
  #     - ./data/dataset/:/app/data/dataset/
  #     - ./data/Spark/:/app/data/Spark
  #   command: ["spark-submit", "--packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.4,org.elasticsearch:elasticsearch-spark-30_2.12:8.17.0", "/app/SparkMLlib.py"]
   

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.17.0
    container_name: elasticsearch_g
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms3g -Xmx3g -XX:+UseG1GC -XX:MaxGCPauseMillis=500
    ports:
      - "9200:9200"
    volumes:
      - ./data/elasticsearch:/usr/share/elasticsearch/data
    mem_limit: 3g
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200/_cluster/health"]
      interval: 10s
      retries: 5
      start_period: 30s
      timeout: 5s

  kibana:
    image: docker.elastic.co/kibana/kibana:8.17.0
    container_name: kibana_g
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200  # URL di connessione a Elasticsearch
    ports:
      - "5601:5601"  # Porta 5601 per l'accesso a Kibana
    volumes:
      - ./data/kibana:/usr/share/kibana/data
    depends_on:
      - elasticsearch 
